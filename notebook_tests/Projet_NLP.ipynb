{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import des bibliothèques nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine learning : Import du fichier généré pour effectuer les tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/nlp_generated_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>sujet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je suis blessé, j’ai besoin d’un centre médica...</td>\n",
       "      <td>santé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je cherche un centre de santé à Paris où je po...</td>\n",
       "      <td>santé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J’ai des pensées suicidaires, je suis à avenue...</td>\n",
       "      <td>santé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y a-t-il un hôpital ou un médecin proche de ru...</td>\n",
       "      <td>santé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je me suis blessé et je saigne. Où aller à Par...</td>\n",
       "      <td>santé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texte  sujet\n",
       "0  Je suis blessé, j’ai besoin d’un centre médica...  santé\n",
       "1  Je cherche un centre de santé à Paris où je po...  santé\n",
       "2  J’ai des pensées suicidaires, je suis à avenue...  santé\n",
       "3  Y a-t-il un hôpital ou un médecin proche de ru...  santé\n",
       "4  Je me suis blessé et je saigne. Où aller à Par...  santé"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine learning : Nettoyage du fichier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   texte   2000 non-null   object\n",
      " 1   sujet   2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [texte, sujet]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   texte   2000 non-null   object\n",
      " 1   sujet   2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# On vérifie si la colonne contient des doublons et on les traite s'il y en a.\n",
    "\n",
    "filtered_df = df[df['texte'].isna()]\n",
    "print(filtered_df)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texte\n",
      "<class 'str'>    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# On vérifie qu'on a bien que des valeurs avec un type String\n",
    "\n",
    "print(df['texte'].apply(type).value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP : Chargement du modèle français de spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")  # Chargement du modèle français\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP : Réception d'un texte en entrée**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous : Je cherche les horaires d’une maraude dans Paris, si possible près de rue de Robin.\n"
     ]
    }
   ],
   "source": [
    "#received_text = input(\"Bonjour ! Que puis-je faire pour vous ?\")\n",
    "# Etant actuellement dans un Jupyter notebook, le input() n'est pas supporté donc je simule une réponse manuellement.\n",
    "\n",
    "received_text = \"Je cherche les horaires d’une maraude dans Paris, si possible près de rue de Robin.\"\n",
    "print(\"Vous :\", received_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je → lemma: je, POS: PRON\n",
      "cherche → lemma: cherche, POS: VERB\n",
      "les → lemma: le, POS: DET\n",
      "horaires → lemma: horaire, POS: NOUN\n",
      "d’ → lemma: d’, POS: ADV\n",
      "une → lemma: un, POS: DET\n",
      "maraude → lemma: maraude, POS: NOUN\n",
      "dans → lemma: dans, POS: ADP\n",
      "paris → lemma: paris, POS: PROPN\n",
      ", → lemma: ,, POS: PUNCT\n",
      "si → lemma: si, POS: SCONJ\n",
      "possible → lemma: possible, POS: ADJ\n",
      "près → lemma: près, POS: ADV\n",
      "de → lemma: de, POS: ADP\n",
      "rue → lemma: rue, POS: NOUN\n",
      "de → lemma: de, POS: ADP\n",
      "robin → lemma: robin, POS: PROPN\n",
      ". → lemma: ., POS: PUNCT\n"
     ]
    }
   ],
   "source": [
    "spacy_doc = nlp(received_text)\n",
    "\n",
    "for token in spacy_doc : \n",
    "    print(f\"{token.text.lower()} → lemma: {token.lemma_.lower()}, POS: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris → label: LOC\n",
      "Robin → label: PER\n"
     ]
    }
   ],
   "source": [
    "for ent in spacy_doc.ents:\n",
    "    print(f\"{ent.text} → label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIEUX DÉTECTÉS : ['Paris']\n"
     ]
    }
   ],
   "source": [
    "lieux = [ent.text for ent in spacy_doc.ents if ent.label_ in [\"GPE\", \"LOC\", \"FAC\"]]\n",
    "print(\"LIEUX DÉTECTÉS :\", lieux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte nettoyé : cherche horaire maraude paris rue robin\n"
     ]
    }
   ],
   "source": [
    "clean_text = \" \".join([\n",
    "    token.lemma_.lower() for token in spacy_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "])\n",
    "print(\"Texte nettoyé :\", clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas sûre de garder cette partie sur TfidfVectorizer. On a trop de lignes et trop de caractères par ligne pour pouvoir voir quelque chose j pense\n",
    "\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#X = vectorizer.fit_transform(df[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vectorizer.get_feature_names_out())  # Liste des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.toarray()[10:30])  # Matrice TF-IDF sur un échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nfrom transformers import pipeline\\nclassifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\\n\\nresult = classifier(\"J\\'adore ce produit, il est excellent !\")\\nprint(result)\\n\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    " \n",
    "result = classifier(\"J'adore ce produit, il est excellent !\")\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
